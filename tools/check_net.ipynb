{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "import shutil\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils.losses as losses\n",
    "import utils.detectors as detectors\n",
    "import utils.metrics as metrics\n",
    "import utils.optimizer as optim\n",
    "from models.model_builder import getModel\n",
    "from datasets.data_loader import getDataLoader\n",
    "from torchvision import transforms as trn\n",
    "from config import cfg\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict()\n",
    "cfg['network_kind'] = 'wrn'\n",
    "cfg['depth'] = 40\n",
    "cfg['widen_factor'] = 2\n",
    "cfg['num_classes'] = 10\n",
    "cfg['drop_rate'] = 0.3\n",
    "model = getModel(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"/home/sr2/Hyeokjun/OOD-saige/results/wrn_cifar10_baseline/ckpt/checkpoint_epoch_100.pyth\", map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Severstal ready.\n"
     ]
    }
   ],
   "source": [
    "cfg['in_dataset'] = dict()\n",
    "cfg['in_dataset']['dataset'] = 'Severstal'\n",
    "cfg['in_dataset']['targets'] = ['ok','1', '2']\n",
    "cfg['in_dataset']['train_transform'] = trn.Compose([trn.RandomHorizontalFlip(),\n",
    "                                         trn.RandomCrop(224),\n",
    "                                         trn.ToTensor()])\n",
    "cfg['in_dataset']['valid_transform'] = trn.Compose([trn.CenterCrop(224),\n",
    "                                         trn.ToTensor()])\n",
    "cfg['in_dataset']['data_root'] = '/home/sr2/HDD2/Openset/'\n",
    "cfg['in_dataset']['split_root'] = '/home/sr2/Hyeokjun/OOD-saige/datasets/data_split/'\n",
    "\n",
    "# DataLoader config\n",
    "cfg['dataloader'] = dict()\n",
    "cfg['dataloader']['batch_size'] = 20\n",
    "cfg['dataloader']['num_workers'] = 1\n",
    "cfg['dataloader']['pin_memory'] = True\n",
    "\n",
    "\n",
    "in_valid_loader = getDataLoader(ds_cfg=cfg['in_dataset'],\n",
    "                                    dl_cfg=cfg['dataloader'],\n",
    "                                    split=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Dataset CIFAR10 ready.\n"
     ]
    }
   ],
   "source": [
    "cfg['in_dataset'] = dict()\n",
    "cfg['in_dataset']['dataset'] = 'cifar10'\n",
    "cfg['in_dataset']['train_transform'] = trn.Compose([trn.RandomHorizontalFlip(),\n",
    "                                         trn.RandomCrop(32),\n",
    "                                         trn.ToTensor()])\n",
    "cfg['in_dataset']['valid_transform'] = trn.Compose([trn.CenterCrop(32),\n",
    "                                         trn.ToTensor()])\n",
    "cfg['in_dataset']['data_root'] = '/home/sr2/HDD2/Openset/'\n",
    "cfg['in_dataset']['split_root'] = '/home/sr2/Hyeokjun/OOD-saige/datasets/data_split/'\n",
    "\n",
    "# DataLoader config\n",
    "cfg['dataloader'] = dict()\n",
    "cfg['dataloader']['batch_size'] = 20\n",
    "cfg['dataloader']['num_workers'] = 1\n",
    "cfg['dataloader']['pin_memory'] = True\n",
    "\n",
    "\n",
    "in_valid_loader = getDataLoader(ds_cfg=cfg['in_dataset'],\n",
    "                                    dl_cfg=cfg['dataloader'],\n",
    "                                    split=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_iterator = iter(in_valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 6, 5, 6, 0, 9, 3, 9, 7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6])\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9564, 0.9998, 0.9994, 0.9998, 0.9999, 0.9995, 1.0000, 0.9919, 0.9986,\n",
      "        0.9989, 0.9999, 0.9998, 0.5427, 0.9985, 0.9982, 0.9998, 1.0000, 0.9981,\n",
      "        0.5206, 0.7564], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([4, 6, 5, 6, 0, 9, 3, 9, 7, 6, 9, 8, 2, 3, 8, 8, 7, 7, 5, 3],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "(data, target) = next(dataloader_iterator)\n",
    "data = data.cuda()\n",
    "print(target)\n",
    "logit = model(data)\n",
    "print(torch.max(F.softmax(logit, dim=1),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.0000, 0.9999, 0.9959, 0.9892, 0.9997, 0.9834, 0.7740, 0.9998, 0.9841,\n",
       "        0.8313, 0.9996, 0.8667, 0.7877, 0.9940, 1.0000, 1.0000, 0.9438, 0.9982,\n",
       "        0.9328, 0.9999], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.rand(5,5)\n",
    "targets = torch.randint(low=0, high=5, size=(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 0, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4453, 0.9073, 0.7540, 0.9985, 0.8467],\n",
       "        [0.5723, 0.3505, 0.0739, 0.8080, 0.7474],\n",
       "        [0.1585, 0.6632, 0.3531, 0.4824, 0.9365],\n",
       "        [0.8888, 0.2350, 0.2890, 0.0142, 0.1104],\n",
       "        [0.3963, 0.1644, 0.6500, 0.1196, 0.5480]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (logits.max(dim=1).indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = ((logits.max(dim=1).indices) != targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False,  True,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "print(wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred [3] tar [2]\n",
      "pred [4] tar [0]\n",
      "pred [0] tar [2]\n",
      "pred [2] tar [3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, i in enumerate(wrong):\n",
    "    if i:\n",
    "        print(\"pred [{}] tar [{}]\".format(pred[idx], targets[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ood",
   "language": "python",
   "name": "ood"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
