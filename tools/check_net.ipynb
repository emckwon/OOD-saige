{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "import shutil\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils.losses as losses\n",
    "import utils.detectors as detectors\n",
    "import utils.metrics as metrics\n",
    "import utils.optimizer as optim\n",
    "from models.model_builder import getModel\n",
    "from datasets.data_loader import getDataLoader\n",
    "from torchvision import transforms as trn\n",
    "from config import cfg\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict()\n",
    "cfg['network_kind'] = 'wrn'\n",
    "cfg['depth'] = 40\n",
    "cfg['widen_factor'] = 2\n",
    "cfg['num_classes'] = 10\n",
    "cfg['drop_rate'] = 0.3\n",
    "model = getModel(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"/home/sr2/Hyeokjun/OOD-saige/results/wrn_cifar10_baseline/ckpt/checkpoint_epoch_100.pyth\", map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Severstal ready.\n"
     ]
    }
   ],
   "source": [
    "cfg['in_dataset'] = dict()\n",
    "cfg['in_dataset']['dataset'] = 'Severstal'\n",
    "cfg['in_dataset']['targets'] = ['ok','1', '2']\n",
    "cfg['in_dataset']['train_transform'] = trn.Compose([trn.RandomHorizontalFlip(),\n",
    "                                         trn.RandomCrop(224),\n",
    "                                         trn.ToTensor()])\n",
    "cfg['in_dataset']['valid_transform'] = trn.Compose([trn.CenterCrop(224),\n",
    "                                         trn.ToTensor()])\n",
    "cfg['in_dataset']['data_root'] = '/home/sr2/HDD2/Openset/'\n",
    "cfg['in_dataset']['split_root'] = '/home/sr2/Hyeokjun/OOD-saige/datasets/data_split/'\n",
    "\n",
    "# DataLoader config\n",
    "cfg['dataloader'] = dict()\n",
    "cfg['dataloader']['batch_size'] = 20\n",
    "cfg['dataloader']['num_workers'] = 1\n",
    "cfg['dataloader']['pin_memory'] = True\n",
    "\n",
    "\n",
    "in_valid_loader = getDataLoader(ds_cfg=cfg['in_dataset'],\n",
    "                                    dl_cfg=cfg['dataloader'],\n",
    "                                    split=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Dataset CIFAR10 ready.\n"
     ]
    }
   ],
   "source": [
    "cfg['in_dataset'] = dict()\n",
    "cfg['in_dataset']['dataset'] = 'cifar10'\n",
    "cfg['in_dataset']['train_transform'] = trn.Compose([trn.RandomHorizontalFlip(),\n",
    "                                         trn.RandomCrop(32),\n",
    "                                         trn.ToTensor()])\n",
    "cfg['in_dataset']['valid_transform'] = trn.Compose([trn.CenterCrop(32),\n",
    "                                         trn.ToTensor()])\n",
    "cfg['in_dataset']['data_root'] = '/home/sr2/HDD2/Openset/'\n",
    "cfg['in_dataset']['split_root'] = '/home/sr2/Hyeokjun/OOD-saige/datasets/data_split/'\n",
    "\n",
    "# DataLoader config\n",
    "cfg['dataloader'] = dict()\n",
    "cfg['dataloader']['batch_size'] = 20\n",
    "cfg['dataloader']['num_workers'] = 1\n",
    "cfg['dataloader']['pin_memory'] = True\n",
    "\n",
    "\n",
    "in_valid_loader = getDataLoader(ds_cfg=cfg['in_dataset'],\n",
    "                                    dl_cfg=cfg['dataloader'],\n",
    "                                    split=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_iterator = iter(in_valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 6, 5, 6, 0, 9, 3, 9, 7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6])\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9564, 0.9998, 0.9994, 0.9998, 0.9999, 0.9995, 1.0000, 0.9919, 0.9986,\n",
      "        0.9989, 0.9999, 0.9998, 0.5427, 0.9985, 0.9982, 0.9998, 1.0000, 0.9981,\n",
      "        0.5206, 0.7564], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([4, 6, 5, 6, 0, 9, 3, 9, 7, 6, 9, 8, 2, 3, 8, 8, 7, 7, 5, 3],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "(data, target) = next(dataloader_iterator)\n",
    "data = data.cuda()\n",
    "print(target)\n",
    "logit = model(data)\n",
    "print(torch.max(F.softmax(logit, dim=1),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 3\n",
    "out_features = 5\n",
    "in_features = 10\n",
    "alpha = 1\n",
    "# weights = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "# bias = nn.Parameter(torch.Tensor(out_features))\n",
    "weights = torch.rand((out_features, in_features))\n",
    "bias = torch.rand((out_features,))\n",
    "features = torch.rand((bs, in_features))\n",
    "\n",
    "def euclidean_distances(features, prototypes, pnorm):\n",
    "    return F.pairwise_distance(features.unsqueeze(2), prototypes.t().unsqueeze(0), p=pnorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2792, 0.5562, 0.5294, 0.2019, 0.0070, 0.6183, 0.1054, 0.3990, 0.7386,\n",
       "         0.2678],\n",
       "        [0.4292, 0.6393, 0.4971, 0.3767, 0.9255, 0.3906, 0.0946, 0.7144, 0.4681,\n",
       "         0.3511],\n",
       "        [0.2815, 0.5964, 0.9384, 0.5961, 0.6422, 0.8453, 0.6853, 0.9122, 0.9689,\n",
       "         0.5580],\n",
       "        [0.6468, 0.9789, 0.8526, 0.0362, 0.8766, 0.9725, 0.0280, 0.0522, 0.3910,\n",
       "         0.4061],\n",
       "        [0.5719, 0.6909, 0.1939, 0.1932, 0.4687, 0.8602, 0.8138, 0.1008, 0.5467,\n",
       "         0.2539]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "targets = torch.randint(low=0, high=5, size=(bs,))\n",
    "print(targets)\n",
    "targets_one_hot = torch.eye(weights.size(0))[targets]\n",
    "# affine = features.matmul(weights.t()) + bias\n",
    "# intra_inter_affine = torch.where(targets_one_hot != 0, affine, torch.Tensor([float('Inf')]))\n",
    "# intra_affines = intra_inter_affine[intra_inter_affine != float('Inf')]\n",
    "# intra_inter_affine = torch.where(targets_one_hot != 0, torch.Tensor([float('Inf')]), affine)\n",
    "# inter_affines = intra_inter_affine[intra_inter_affine != float('Inf')]\n",
    "# transformed_affines = affine\n",
    "# print(alpha * transformed_affines)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = euclidean_distances(features, weights, 2)\n",
    "intra_inter_distances = torch.where(targets_one_hot != 0, -distances, distances)\n",
    "intra_distances = -intra_inter_distances[intra_inter_distances < 0]\n",
    "inter_distances = intra_inter_distances[intra_inter_distances > 0]\n",
    "transformed_distances = distances\n",
    "regularization = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3094, -1.2153, -1.3058, -1.3996, -1.1051],\n",
       "        [-1.1597, -0.9348, -1.5069, -0.8814, -1.0158],\n",
       "        [-1.3925, -1.3281, -1.1230, -1.7164, -1.2605]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3094,  1.2153,  1.3058,  1.3996,  1.1051],\n",
       "        [ 1.1597, -0.9348,  1.5069,  0.8814,  1.0158],\n",
       "        [ 1.3925, -1.3281,  1.1230,  1.7164,  1.2605]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intra_inter_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3094, 0.9348, 1.3281])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intra_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2153, 1.3058, 1.3996, 1.1051, 1.1597, 1.5069, 0.8814, 1.0158, 1.3925,\n",
       "        1.1230, 1.7164, 1.2605])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ood",
   "language": "python",
   "name": "ood"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
